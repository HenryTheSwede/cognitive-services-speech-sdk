{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "import logging\n",
    "try:\n",
    "    import customvoice\n",
    "except ImportError:\n",
    "    print('Pleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.' )\n",
    "    quit()\n",
    "import azure.cognitiveservices.speech as speechsdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_personal_voice(project_id: str,\n",
    "                          consent_id: str, consent_file_path: str, voice_talent_name: str, company_name: str,\n",
    "                          personal_voice_id: str, audio_folder: str):\n",
    "    # create project\n",
    "    project = customvoice.Project.create(config, project_id, customvoice.ProjectKind.PersonalVoice)\n",
    "    print('Project created. project id: %s' % project.id)\n",
    "\n",
    "    # upload consent\n",
    "    consent = customvoice.Consent.create(config, project_id, consent_id, voice_talent_name, company_name, consent_file_path, 'en-us')\n",
    "    if consent.status == customvoice.Status.Failed:\n",
    "        print('Create consent failed. consent id: %s' % consent.id)\n",
    "        raise Exception\n",
    "    elif consent.status == customvoice.Status.Succeeded:\n",
    "        print('Create consent succeeded. consent id: %s' % consent.id)\n",
    "\n",
    "    # create personal voice\n",
    "    personal_voice = customvoice.PersonalVoice.create(config, project_id, personal_voice_id, consent_id, audio_folder)\n",
    "    if personal_voice.status == customvoice.Status.Failed:\n",
    "        print('Create personal voice failed. personal voice id: %s' % personal_voice.id)\n",
    "        raise Exception\n",
    "    elif personal_voice.status == customvoice.Status.Succeeded:\n",
    "        print('Create personal voice succeeded. personal voice id: %s, speaker profile id: %s' % (personal_voice.id, personal_voice.speaker_profile_id))\n",
    "    return personal_voice.speaker_profile_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def speech_synthesis_to_wave_file(text: str, output_file_path: str, speaker_profile_id: str):\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=config.key, region=config.region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=output_file_path)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "\n",
    "    # use PhoenixLatestNeural if you want word boundary event.  We will support events on DragonLatestNeural in the future.\n",
    "    ssml = \"<speak version='1.0' xml:lang='en-US' xmlns='http://www.w3.org/2001/10/synthesis' \" \\\n",
    "           \"xmlns:mstts='http://www.w3.org/2001/mstts'>\" \\\n",
    "           \"<voice name='DragonLatestNeural'>\" \\\n",
    "           \"<mstts:ttsembedding speakerProfileId='%s'/>\" \\\n",
    "           \"<mstts:express-as style='Prompt'>\" \\\n",
    "           \"<lang xml:lang='en-US'> %s </lang>\" \\\n",
    "           \"</mstts:express-as>\" \\\n",
    "           \"</voice></speak> \" % (speaker_profile_id, text)\n",
    "\n",
    "    def word_boundary(evt):\n",
    "        print(f\"Word Boundary: Text='{evt.text}', Audio offset={evt.audio_offset / 10000}ms, Duration={evt.duration / 10000}ms, text={evt.text}\")\n",
    "\n",
    "    speech_synthesizer.synthesis_word_boundary.connect(word_boundary)\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "    # Check result\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, output_file_path))\n",
    "        print(\"result id: {}\".format(result.result_id))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"result id: {}\".format(result.result_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_up(project_id: str, consent_id: str, personal_voice_id: str):\n",
    "    customvoice.PersonalVoice.delete(config, personal_voice_id)\n",
    "    customvoice.Consent.delete(config, consent_id)\n",
    "    customvoice.Project.delete(config, project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "region = 'eastus' # eastus, westeurope, southeastasia\n",
    "key = '38acf93326ad4b6b97d32f04aa64dd78'\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"customvoice.log\",\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filemode='w')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "config = customvoice.Config(key, region, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "project_id = 'personal-voice-project-1'\n",
    "consent_id = 'personal-voice-consent-1'\n",
    "personal_voice_id  = 'personal-voice-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created. project id: personal-voice-project-1\n",
      "Create consent succeeded. consent id: personal-voice-consent-1\n",
      "Create personal voice failed. personal voice id: personal-voice-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # step 1: create personal voice\n",
    "    # Need consent file and audio file to create personal vocie.\n",
    "    # This is consent file template.\n",
    "    # I [voice talent name] am aware that recordings of my voice will be used by [company name] to create and use a synthetic version of my voice.\n",
    "    # You can find sample consent file here\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/VoiceTalentVerbalStatement.wav\n",
    "    consent_file_path = r'/workspaces/cognitive-services-speech-sdk/samples/custom-voice/python/TestData/VoiceTalentVerbalStatement.wav'\n",
    "    voice_talent_name = 'Sample Voice Actor'\n",
    "    company_name = 'Contoso'\n",
    "\n",
    "    # Need 5 - 90 seconds audio file.\n",
    "    # You can find sample audio file here.\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/SampleAudios.zip\n",
    "    audio_folder = r'/workspaces/cognitive-services-speech-sdk/samples/custom-voice/python/TestData/voice'\n",
    "    speaker_profile_id = create_personal_voice(project_id, \n",
    "                                            consent_id, consent_file_path, voice_talent_name, company_name,\n",
    "                                            personal_voice_id, audio_folder)\n",
    "\n",
    "    # step 2: synthesis wave\n",
    "    text = 'This is zero shot voice. Test 2.'\n",
    "    output_wave_file_path = 'output_sdk.wav'\n",
    "    speech_synthesis_to_wave_file(text, output_wave_file_path, speaker_profile_id)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#finally:\n",
    "    # Optional step 3: clean up, if you don't need this voice to synthesis more content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_up(project_id, consent_id, personal_voice_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice ID: personal-voice-1\n",
      "Speaker Profile ID: eb1a0a5d-60a3-4b5c-849d-f26ef5941b0f\n",
      "Status: Status.Failed\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "personal_voices = customvoice.PersonalVoice.list(config)\n",
    "for voice in personal_voices:\n",
    "    print(f\"Voice ID: {voice.id}\")\n",
    "    print(f\"Speaker Profile ID: {voice.speaker_profile_id}\")\n",
    "    print(f\"Status: {voice.status}\")\n",
    "    print(\"------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
